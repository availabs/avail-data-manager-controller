#!/usr/bin/env node

/* eslint-disable @typescript-eslint/no-var-requires */

require("ts-node").register();
require("tsconfig-paths").register();

const { writeFileSync } = require("fs");
const { join, isAbsolute } = require("path");

const yargs = require("yargs/yargs");
const { hideBin } = require("yargs/helpers");

const dedent = require("dedent");

const dama_events = require("data_manager/events").default;
const logger = require("data_manager/logger").default;

const dama_host_id = require("constants/damaHostId").default;

const { runInDamaContext } = require("data_manager/contexts");

const {
  extract,
  getGeoDatasetMetadata,
  getLayerNames,
  getTableDescriptor,
  persistLayerTableDescriptor,
} = require("./subtasks");

const table_schema = "usgs_national_hydrography_dataset";

const { pg_env, file_path, logging_level } = yargs(hideBin(process.argv))
  // .usage(
  // // "Usage $0 --pg_env [PostgresSQL Database] --etl_context_id [Etl Context ID]"
  // )
  .strict()
  .options({
    pg_env: {
      alias: "p",
      describe: "The PostgresSQL Database",
      demandOption: true,
    },

    file_path: {
      alias: "f",
      describe:
        "The location of the USGS National Hydrography Dataset Best Resolution (NHD) - New York FileGDB ZIP archive.",
      demandOption: true,
    },

    logging_level: {
      alias: "l",
      describe: "The logging level",
      demandOption: false,
      default: "debug",
      choices: ["error", "warn", "info", "debug", "silly"],
    },
  }).argv;

const absolute_file_path = isAbsolute(file_path)
  ? file_path
  : join(process.cwd(), file_path);

logger.level = logging_level;

async function main() {
  const etl_context_id = await dama_events.spawnEtlContext(null, null, pg_env);

  logger.info(`==> etl_context_id: ${etl_context_id}`);

  const ctx = {
    meta: { pgEnv: pg_env, etl_context_id },
  };

  await runInDamaContext(ctx, async () => {
    const initial_event = {
      type: "dt-national-hydrography-dataset/extract-and-analyze:INITIAL",
      payload: {
        file_path: absolute_file_path,
      },
      meta: { dama_host_id },
    };

    await dama_events.dispatch(initial_event);

    const extract_start_event = {
      type: "dt-national-hydrography-dataset/extract:START",
      payload: {
        file_path: absolute_file_path,
      },
      meta: { dama_host_id },
    };

    await dama_events.dispatch(extract_start_event);

    const extract_done_data = await extract(file_path);

    const { id: extract_id, workDirPath: workdir_path } = extract_done_data;

    const etl_context_id_fpath = join(workdir_path, "etl_context_id");
    writeFileSync(etl_context_id_fpath, `${etl_context_id}`);

    const extract_done_event = {
      type: "dt-national-hydrography-dataset/extract:DONE",
      payload: extract_done_data,
    };

    await dama_events.dispatch(extract_done_event);

    const geodataset_metadata = await getGeoDatasetMetadata(extract_id);

    const got_metadata_event = {
      type: "dt-national-hydrography-dataset/getGeoDatasetMetadata:DONE",
      payload: { geodataset_metadata },
    };

    await dama_events.dispatch(got_metadata_event);

    let layer_names = await getLayerNames(extract_id);

    const default_table_descriptors = await Promise.all(
      layer_names.map((layer_name) =>
        getTableDescriptor(extract_id, layer_name)
      )
    );

    const got_default_table_descriptors_event = {
      type: "dt-national-hydrography-dataset/getTableDescriptors:DONE",
      payload: { default_table_descriptors },
    };

    await dama_events.dispatch(got_default_table_descriptors_event);

    // if (default_table_descriptors.length > 1) {
    // throw new Error(
    // "INVARIANT BROKEN: More than one layer in the bridges GIS dataset."
    // );
    // }

    const revised_table_descriptors = default_table_descriptors.map(
      (table_descriptor) => ({
        ...table_descriptor,
        tableSchema: table_schema,
        tableName: table_descriptor.tableName
          .replace(/.*NHD/, "")
          .toLowerCase(),
      })
    );

    for (const revised_table_descriptor of revised_table_descriptors) {
      await persistLayerTableDescriptor(extract_id, revised_table_descriptor);
    }

    const revised_table_descriptors_event = {
      type: "dt-national-hydrography-dataset/persistRevisedLayerTableDescriptors:DONE",
      payload: { revised_table_descriptors },
    };

    await dama_events.dispatch(revised_table_descriptors_event);

    const final_event = {
      type: "dt-national-hydrography-dataset/extract-and-analyze:FINAL",
      payload: {
        extract_id,
        input_gis_dataset_file_path: absolute_file_path,
        workdir_path,
        geodataset_metadata,
        layer_names,
      },
      meta: { dama_host_id },
    };

    await dama_events.dispatch(final_event);

    console.log(
      JSON.stringify(
        { etl_context_id, extract_id, layer_names, workdir_path },
        null,
        4
      )
    );

    console.log(
      dedent(`
        EXTRACT COMPLETE.
          If required, modify the table_descriptors in the work directory.

            NOTE: If you change table names, you must also update the layerNameToId.json file accordingly.

          When ready, run ./load to load the layers into the database.
      `)
    );
  });
}

main();
